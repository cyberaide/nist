\section{Big Data Usecases}

\TODO{write about how many examples we have and things like
  that. Take from presentation}

define the index numbers

\subsection{Fingerprint Matching (U.N1)}

Fingerprint recognition refers to the automated method for verifying a
match between two fingerprints and that is used to identify
individuals and verify their identity. Fingerprints are the most
widely used form of biometric used to identify individuals. The
automated fingerprint matching generally required the detection of
different fingerprint features (aggregate characteristics of ridges,
and minutia points) and then the use of fingerprint matching
algorithm, which can do both one-to- one and one-to- many matching
operations. Based on the number of matches a proximity score (distance
or similarity) can be calculated. Furthermore, NIST is providing via
the the NIST Fingerprint dataset a special database. The goal for this
usecase is the following: given a set of {\it probe} and {\em gallery}
images, compare the probe images to the gallery images, and report the
matching scores.  The dataset comprises 54,000 images and their
metadata.  It uses MINDTCT \cite{Hyungro:??} preprocesses the images
to identify minutae of the prints automatically locating and recording
ridge ending and bifurcations in a fingerprint image; and BOZORTH3
\cite{Hyungro:??} to identify matches. Both are are part of the NIST
Biometric Image Software (NBIS) \cite{Hyungro:??}.

To execute this usecase we need to deploy an application to analyze
the dataset. It internally uses cloudmesh to deploy an the software
stack The implemented \cite{??} \TODO{Hyungro: make refernce out of
  this
  https://github.com/cloudmesh/example-project-nist-fingerprint-matching}
solution uses a software stack comprising of HDFS, YARN, Apache Spark,
Apache HBase, and Apache drill, Scaka, and the NBIS software. A Hadoop
cluster is deployed and YARN used to schedule Spark jobs that load the
images into HBase, process the images, and compute the matches. Apache
Drill, with the HBase plugin, can then be used to generate reports
with the NBIS tools\cite{??}. The results are stored in HBase and
Apache Drill \cite{??} is used to query the results.  The code
leverages tools and services is based on \cite{??} \TODO{Hyungro: put
  this in the references: the “NIST Big Data Public Working Group
  draft Possible Big Data Use Cases Implementation using NBDRA
  authored by Afzal Godil and Wo Chang”.}  , while significantly
enhance it with cloudmesh deployment strategies and services.

\TODO{Hyungro: create citation for this. http://www.nist.gov/itl/iad/ig/nbis.cfm}


\subsection{U.N2 Face Detection}

This example shows how to deploy the NIST Human and Face Detection with INRIA
Person Dataset to the cluster. OpenCV Python code runs with Spark Map function
to perform distributed job processing on the Mesos scheduler.

\subsubsection{Introduction}
Human detection and face detection have been studied during the last several
years and models for them have improved along with Histograms of Oriented
Gradients (HOG) for Human Detection. OpenCV is a Computer Vision library
including the SVM classifier and the HOG object detector for pedestrian
detection and INRIA Person Dataset is one of popular samples for both
training and testing purposes. In this article, we deployed Apache Spark on
Mesos clusters to train and apply detection models from OpenCV using Python
API.

\subsubsection{Implementation}
INRIA Person Dataset: This dataset contains positive and negative images for
training and test purposes with annotation files for upright persons in each
image. 288 positive test images, 453 negative test images, 614 positive
training images and 1218 negative training images are included along with
normalized 64x128 pixel formats. 970MB dataset is available to download.

HOG with SVM model: Histogram of Oriented Gradient (HOG) and Support Vector
Machine (SVM) are used as object detectors and classifiers and built-in python
libraries from OpenCV provide these models for human detection.

To deploy applications and build clusters for batch-processing large
datasets, Ansible scripts play a big role such as installation and
configuration towards available machines. Ansible provides abstractions by
Playbook Roles and reusability by Include statements. We define X application
in X Ansible Role, for example, and use include statements to combine with
other applications e.g. Y or Z. Five Ansible roles are used in this use case to
build clusters for Human and Face Detection with INRIA dataset. 
The main Ansible playbook runs Ansible roles in order for the following
software stacks:

\begin{itemize}
   \item Apache Spark 
   \item Apache Mesos
   \item Apache Zookeeper
   \item OpenCV (with Python)
\end{itemize}

\subsubsection{Repository}
\begin{itemize}

  \item Ansible Role for Spark: https://github.com/VirtualClusters/ansible-role-spark-for-mesos
  \item Ansible Role for Mesos (with Zookeeper): https://github.com/VirtualClusters/ansible-role-mesos-by-mesosphere
  \item Ansible Role for OpenCV: https://github.com/futuresystems/ansible-role-opencv
  \item Ansible Main Play (Include Statement): https://github.com/futuresystems/pedestrian-and-face-detection

\end{itemize}


